{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Oscillatory Burst Analysis Module\n",
    "\n",
    "This module provides comprehensive analysis of oscillatory bursts in neural time series data.\n",
    "It combines temporal and spectral approaches to characterize burst dynamics across different\n",
    "frequency bands (delta, theta, alpha) with detailed statistical and spectral parameterization.\n",
    "\n",
    "Key Features:\n",
    "- Dual-threshold burst detection with morphological dilation\n",
    "- Frequency-band specific burst analysis (Delta: 1-4Hz, Theta: 4-8Hz, Alpha: 8-13Hz)\n",
    "- Per-burst spectral parameterization using FOOOF/SpectralModel\n",
    "- Comprehensive statistical characterization of burst properties\n",
    "- Automated batch processing with visualization capabilities\n",
    "- Standardized well plate mapping for experimental organization\n",
    "\n",
    "Dependencies:\n",
    "    - numpy, pandas, scipy, matplotlib\n",
    "    - neurodsp (for filtering and spectral analysis)\n",
    "    - specparam (FOOOF algorithm for spectral parameterization)\n",
    "    - scikit-image or scipy.ndimage (for morphological operations)\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Union, Optional, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import hilbert, find_peaks\n",
    "from scipy.ndimage import binary_dilation, gaussian_filter1d, label\n",
    "\n",
    "from neurodsp.filt import filter_signal\n",
    "from neurodsp.spectral import compute_spectrum_welch\n",
    "from specparam import SpectralModel\n",
    "\n",
    "\n",
    "class OscillatoryBurstAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyzes oscillatory bursts in neural time series across multiple frequency bands.\n",
    "    \n",
    "    This analyzer detects transient oscillatory events (bursts) using a dual-threshold\n",
    "    approach combined with frequency-specific filtering. Each detected burst is then\n",
    "    characterized both temporally (duration, frequency) and spectrally (power, slope).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Standard 48-well plate mapping (6 rows x 8 columns)\n",
    "    DEFAULT_PLATEMAP = {\n",
    "        'well00': 'A1', 'well01': 'A2', 'well02': 'A3', 'well03': 'A4', \n",
    "        'well04': 'A5', 'well05': 'A6', 'well06': 'A7', 'well07': 'A8',\n",
    "        'well10': 'B1', 'well11': 'B2', 'well12': 'B3', 'well13': 'B4', \n",
    "        'well14': 'B5', 'well15': 'B6', 'well16': 'B7', 'well17': 'B8',\n",
    "        'well20': 'C1', 'well21': 'C2', 'well22': 'C3', 'well23': 'C4', \n",
    "        'well24': 'C5', 'well25': 'C6', 'well26': 'C7', 'well27': 'C8',\n",
    "        'well30': 'D1', 'well31': 'D2', 'well32': 'D3', 'well33': 'D4', \n",
    "        'well34': 'D5', 'well35': 'D6', 'well36': 'D7', 'well37': 'D8',\n",
    "        'well40': 'E1', 'well41': 'E2', 'well42': 'E3', 'well43': 'E4', \n",
    "        'well44': 'E5', 'well45': 'E6', 'well46': 'E7', 'well47': 'E8',\n",
    "        'well50': 'F1', 'well51': 'F2', 'well52': 'F3', 'well53': 'F4', \n",
    "        'well54': 'F5', 'well55': 'F6', 'well56': 'F7', 'well57': 'F8'\n",
    "    }\n",
    "    \n",
    "    # Default frequency band definitions with analysis parameters\n",
    "    DEFAULT_FREQUENCY_BANDS = {\n",
    "        'Delta': {\n",
    "            'freq_range': (1, 4),\n",
    "            'min_cycles': 8,        # Minimum cycles for valid burst\n",
    "            'cycles_dont_drop': 3   # Cycles to bridge gaps in detection\n",
    "        },\n",
    "        'Theta': {\n",
    "            'freq_range': (4, 8),\n",
    "            'min_cycles': 16,\n",
    "            'cycles_dont_drop': 4\n",
    "        },\n",
    "        'Alpha': {\n",
    "            'freq_range': (8, 13),\n",
    "            'min_cycles': 24,\n",
    "            'cycles_dont_drop': 5\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    def __init__(self, \n",
    "                 base_path: Union[str, Path] = None,\n",
    "                 output_subdir: str = \"burst_analysis\",\n",
    "                 frequency_bands: Dict = None,\n",
    "                 platemap: Dict = None):\n",
    "        \"\"\"\n",
    "        Initialize the oscillatory burst analyzer.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        base_path : str or Path, optional\n",
    "            Base directory for data processing\n",
    "        output_subdir : str\n",
    "            Subdirectory name for output files\n",
    "        frequency_bands : dict, optional\n",
    "            Custom frequency band definitions. Uses defaults if None.\n",
    "        platemap : dict, optional\n",
    "            Custom well-to-name mapping. Uses standard 48-well format if None.\n",
    "        \"\"\"\n",
    "        self.base_path = Path(base_path) if base_path else Path.cwd()\n",
    "        self.output_dir = self.base_path / output_subdir\n",
    "        self.plots_dir = self.output_dir / \"plots\"\n",
    "        \n",
    "        self.frequency_bands = frequency_bands or self.DEFAULT_FREQUENCY_BANDS\n",
    "        self.platemap = platemap or self.DEFAULT_PLATEMAP\n",
    "        \n",
    "        self.setup_logging()\n",
    "        \n",
    "    def setup_logging(self):\n",
    "        \"\"\"Configure logging for analysis tracking.\"\"\"\n",
    "        log_file = self.base_path / f'burst_analysis_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log'\n",
    "        \n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "            handlers=[\n",
    "                logging.FileHandler(log_file),\n",
    "                logging.StreamHandler()\n",
    "            ]\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def compute_amplitude_envelope(self, signal: np.ndarray, \n",
    "                                 sampling_rate: float,\n",
    "                                 freq_range: Tuple[float, float]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute amplitude envelope with frequency-adaptive smoothing.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        signal : np.ndarray\n",
    "            Input signal\n",
    "        sampling_rate : float\n",
    "            Sampling rate in Hz\n",
    "        freq_range : tuple\n",
    "            (low_freq, high_freq) for the frequency band\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        np.ndarray\n",
    "            Smoothed amplitude envelope\n",
    "        \"\"\"\n",
    "        # Calculate amplitude envelope using Hilbert transform\n",
    "        analytic_signal = hilbert(signal)\n",
    "        amplitude_envelope = np.abs(analytic_signal)\n",
    "        \n",
    "        # Frequency-adaptive Gaussian smoothing\n",
    "        low_freq, high_freq = freq_range\n",
    "        center_freq = (low_freq + high_freq) / 2\n",
    "        bandwidth = high_freq - low_freq\n",
    "        \n",
    "        # Adaptive smoothing sigma based on frequency characteristics\n",
    "        sigma = sampling_rate * (0.4 / center_freq + 0.2 * (bandwidth / center_freq))\n",
    "        smoothed_envelope = gaussian_filter1d(amplitude_envelope, sigma)\n",
    "        \n",
    "        return smoothed_envelope\n",
    "\n",
    "    def detect_bursts_dual_threshold(self, \n",
    "                                   amplitude_envelope: np.ndarray,\n",
    "                                   sampling_rate: float,\n",
    "                                   freq_range: Tuple[float, float],\n",
    "                                   min_cycles: int,\n",
    "                                   cycles_dont_drop: int,\n",
    "                                   low_percentile: float = 50,\n",
    "                                   high_percentile: float = 75) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Detect oscillatory bursts using dual-threshold method with morphological operations.\n",
    "        \n",
    "        This method:\n",
    "        1. Sets thresholds based on amplitude distribution percentiles\n",
    "        2. Identifies candidate regions above low threshold containing high threshold crossings\n",
    "        3. Applies morphological dilation to bridge brief gaps\n",
    "        4. Filters bursts by minimum duration requirements\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        amplitude_envelope : np.ndarray\n",
    "            Smoothed amplitude envelope\n",
    "        sampling_rate : float\n",
    "            Sampling rate in Hz\n",
    "        freq_range : tuple\n",
    "            (low_freq, high_freq) for minimum cycle calculations\n",
    "        min_cycles : int\n",
    "            Minimum number of cycles for a valid burst\n",
    "        cycles_dont_drop : int\n",
    "            Number of cycles to bridge gaps in detection\n",
    "        low_percentile : float\n",
    "            Percentile for low threshold (default: 50th percentile)\n",
    "        high_percentile : float\n",
    "            Percentile for high threshold (default: 75th percentile)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        np.ndarray\n",
    "            Boolean array indicating burst periods\n",
    "        \"\"\"\n",
    "        # Calculate thresholds from amplitude distribution\n",
    "        low_threshold = np.percentile(amplitude_envelope, low_percentile)\n",
    "        high_threshold = np.percentile(amplitude_envelope, high_percentile)\n",
    "        \n",
    "        # Pre-calculate cycle-based parameters\n",
    "        freq_low = freq_range[0]  # Use lowest frequency for conservative estimates\n",
    "        samples_per_cycle = sampling_rate / freq_low\n",
    "        max_drop_samples = int(cycles_dont_drop * samples_per_cycle)\n",
    "        min_duration_samples = int(min_cycles * samples_per_cycle)\n",
    "        \n",
    "        # Create morphological structure for dilation\n",
    "        dilation_structure = np.ones(max_drop_samples)\n",
    "        \n",
    "        # Initialize burst detection array\n",
    "        is_burst = np.zeros_like(amplitude_envelope, dtype=bool)\n",
    "        \n",
    "        # Find regions above thresholds\n",
    "        high_threshold_crossings = amplitude_envelope >= high_threshold\n",
    "        low_threshold_crossings = amplitude_envelope >= low_threshold\n",
    "        \n",
    "        # Label connected regions above low threshold\n",
    "        labeled_regions, num_regions = label(low_threshold_crossings)\n",
    "        \n",
    "        # Process each potential burst region\n",
    "        for region_id in range(1, num_regions + 1):\n",
    "            region_mask = labeled_regions == region_id\n",
    "            \n",
    "            # Check if region contains high threshold crossings\n",
    "            if np.any(high_threshold_crossings[region_mask]):\n",
    "                # Apply morphological dilation to bridge gaps\n",
    "                dilated_region = binary_dilation(region_mask, structure=dilation_structure)\n",
    "                \n",
    "                # Ensure we only get the connected component containing original region\n",
    "                connected_labels, _ = label(dilated_region)\n",
    "                original_label = connected_labels[region_mask][0]\n",
    "                final_region = connected_labels == original_label\n",
    "                \n",
    "                # Check minimum duration requirement\n",
    "                if np.sum(final_region) >= min_duration_samples:\n",
    "                    is_burst[final_region] = True\n",
    "        \n",
    "        return is_burst\n",
    "\n",
    "    def compute_burst_statistics(self, \n",
    "                               is_burst: np.ndarray, \n",
    "                               sampling_rate: float,\n",
    "                               freq_range: Tuple[float, float],\n",
    "                               cycles_dont_drop: int) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Compute comprehensive burst statistics.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        is_burst : np.ndarray\n",
    "            Boolean array indicating burst periods\n",
    "        sampling_rate : float\n",
    "            Sampling rate in Hz\n",
    "        freq_range : tuple\n",
    "            Frequency range for the analysis band\n",
    "        cycles_dont_drop : int\n",
    "            Cycles parameter used in detection\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            Dictionary containing burst statistics\n",
    "        \"\"\"\n",
    "        # Apply same dilation as in detection for consistent measurement\n",
    "        freq_low = freq_range[1]  # Use high frequency for gap bridging\n",
    "        samples_per_cycle = sampling_rate / freq_low\n",
    "        max_drop_samples = int(cycles_dont_drop * samples_per_cycle)\n",
    "        dilation_structure = np.ones(max_drop_samples)\n",
    "        \n",
    "        is_burst_merged = binary_dilation(is_burst, structure=dilation_structure)\n",
    "        \n",
    "        # Find burst segments\n",
    "        burst_edges = np.diff(is_burst_merged.astype(int))\n",
    "        burst_starts = np.where(burst_edges == 1)[0] + 1\n",
    "        burst_ends = np.where(burst_edges == -1)[0] + 1\n",
    "        \n",
    "        # Handle edge cases\n",
    "        if is_burst_merged[0]:\n",
    "            burst_starts = np.insert(burst_starts, 0, 0)\n",
    "        if is_burst_merged[-1]:\n",
    "            burst_ends = np.append(burst_ends, len(is_burst_merged))\n",
    "        \n",
    "        # Calculate durations in seconds\n",
    "        durations = (burst_ends - burst_starts) / sampling_rate\n",
    "        total_recording_time = len(is_burst_merged) / sampling_rate\n",
    "        \n",
    "        return {\n",
    "            'n_bursts': int(len(durations)),\n",
    "            'duration_mean': float(np.mean(durations) if len(durations) > 0 else 0),\n",
    "            'duration_std': float(np.std(durations) if len(durations) > 0 else 0),\n",
    "            'percent_burst': float(100 * np.mean(is_burst_merged)),\n",
    "            'bursts_per_second': float(len(durations) / total_recording_time)\n",
    "        }\n",
    "\n",
    "    def analyze_burst_spectra(self, \n",
    "                            signal: np.ndarray,\n",
    "                            is_burst: np.ndarray,\n",
    "                            sampling_rate: float,\n",
    "                            freq_range: Tuple[float, float]) -> Dict[str, List[float]]:\n",
    "        \"\"\"\n",
    "        Analyze spectral properties of individual bursts.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        signal : np.ndarray\n",
    "            Original (unfiltered) signal\n",
    "        is_burst : np.ndarray\n",
    "            Boolean array indicating burst periods\n",
    "        sampling_rate : float\n",
    "            Sampling rate in Hz\n",
    "        freq_range : tuple\n",
    "            Frequency range for peak detection\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            Dictionary containing lists of per-burst spectral parameters\n",
    "        \"\"\"\n",
    "        # Find connected burst segments\n",
    "        labeled_bursts, num_bursts = label(is_burst)\n",
    "        \n",
    "        # Initialize lists for burst-wise parameters\n",
    "        burst_offsets = []\n",
    "        burst_exponents = []\n",
    "        burst_r_squared = []\n",
    "        burst_peak_freqs = []\n",
    "        burst_peak_powers = []\n",
    "        \n",
    "        for burst_id in range(1, num_bursts + 1):\n",
    "            burst_mask = labeled_bursts == burst_id\n",
    "            burst_indices = np.where(burst_mask)[0]\n",
    "            \n",
    "            if len(burst_indices) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Extract burst segment from original signal\n",
    "            burst_start, burst_end = burst_indices[0], burst_indices[-1]\n",
    "            burst_segment = signal[burst_start:burst_end]\n",
    "            \n",
    "            # Only analyze bursts longer than 1 second for reliable spectral estimation\n",
    "            if len(burst_segment) < sampling_rate:\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                # Compute power spectrum for this burst\n",
    "                nperseg = min(len(burst_segment), int(sampling_rate * 4))\n",
    "                noverlap = nperseg // 2\n",
    "                \n",
    "                frequencies, power_spectrum = compute_spectrum_welch(\n",
    "                    burst_segment, \n",
    "                    sampling_rate,\n",
    "                    avg_type='median',\n",
    "                    window='hann',\n",
    "                    nperseg=nperseg,\n",
    "                    noverlap=noverlap,\n",
    "                    f_range=[0.05, 40]\n",
    "                )\n",
    "                \n",
    "                # Fit SpectralModel to burst\n",
    "                burst_spectral_model = SpectralModel(\n",
    "                    peak_width_limits=[1, 8],\n",
    "                    min_peak_height=0.2,\n",
    "                    max_n_peaks=4,\n",
    "                    peak_threshold=1.5,\n",
    "                    aperiodic_mode='fixed'\n",
    "                )\n",
    "                \n",
    "                burst_spectral_model.fit(frequencies, power_spectrum, [0.5, 13])\n",
    "                \n",
    "                # Extract aperiodic parameters\n",
    "                offset, exponent = burst_spectral_model.get_params('aperiodic_params')\n",
    "                burst_offsets.append(offset)\n",
    "                burst_exponents.append(exponent)\n",
    "                burst_r_squared.append(burst_spectral_model.r_squared_)\n",
    "                \n",
    "                # Find peak in frequency band using flattened spectrum\n",
    "                band_mask = ((frequencies >= freq_range[0]) & \n",
    "                           (frequencies <= freq_range[1]))\n",
    "                \n",
    "                if np.any(band_mask):\n",
    "                    band_frequencies = frequencies[band_mask]\n",
    "                    flattened_spectrum = burst_spectral_model._spectrum_flat[band_mask]\n",
    "                    \n",
    "                    # Find maximum in the frequency band\n",
    "                    peak_index = np.argmax(flattened_spectrum)\n",
    "                    peak_frequency = band_frequencies[peak_index]\n",
    "                    peak_power = flattened_spectrum[peak_index]\n",
    "                    \n",
    "                    burst_peak_freqs.append(peak_frequency)\n",
    "                    burst_peak_powers.append(peak_power)\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"Failed to analyze burst spectrum: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        return {\n",
    "            'offsets': burst_offsets,\n",
    "            'exponents': burst_exponents,\n",
    "            'r_squared': burst_r_squared,\n",
    "            'peak_frequencies': burst_peak_freqs,\n",
    "            'peak_powers': burst_peak_powers\n",
    "        }\n",
    "\n",
    "    def analyze_frequency_band(self, \n",
    "                             signal: np.ndarray, \n",
    "                             sampling_rate: float,\n",
    "                             band_name: str,\n",
    "                             band_params: Dict) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Complete analysis pipeline for a single frequency band.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        signal : np.ndarray\n",
    "            Input neural signal\n",
    "        sampling_rate : float\n",
    "            Sampling rate in Hz\n",
    "        band_name : str\n",
    "            Name of frequency band (e.g., 'Delta', 'Theta', 'Alpha')\n",
    "        band_params : dict\n",
    "            Parameters for this frequency band\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            Comprehensive analysis results for this frequency band\n",
    "        \"\"\"\n",
    "        freq_range = band_params['freq_range']\n",
    "        min_cycles = band_params['min_cycles']\n",
    "        cycles_dont_drop = band_params['cycles_dont_drop']\n",
    "        \n",
    "        # Filter signal for burst detection\n",
    "        try:\n",
    "            filtered_signal = filter_signal(\n",
    "                signal, sampling_rate, \n",
    "                pass_type='bandpass', \n",
    "                f_range=freq_range,\n",
    "                filter_type='fir', \n",
    "                remove_edges=True\n",
    "            )\n",
    "            \n",
    "            # Remove NaN values from filtering\n",
    "            valid_indices = ~np.isnan(filtered_signal)\n",
    "            filtered_signal = filtered_signal[valid_indices]\n",
    "            original_signal_trimmed = signal[valid_indices]\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to filter signal for {band_name}: {str(e)}\")\n",
    "            return self._create_empty_band_results()\n",
    "        \n",
    "        if len(filtered_signal) == 0:\n",
    "            self.logger.warning(f\"No valid signal after filtering for {band_name}\")\n",
    "            return self._create_empty_band_results()\n",
    "        \n",
    "        # Compute amplitude envelope\n",
    "        amplitude_envelope = self.compute_amplitude_envelope(\n",
    "            filtered_signal, sampling_rate, freq_range\n",
    "        )\n",
    "        \n",
    "        # Detect bursts\n",
    "        is_burst = self.detect_bursts_dual_threshold(\n",
    "            amplitude_envelope, sampling_rate, freq_range, \n",
    "            min_cycles, cycles_dont_drop\n",
    "        )\n",
    "        \n",
    "        # Compute basic burst statistics\n",
    "        burst_stats = self.compute_burst_statistics(\n",
    "            is_burst, sampling_rate, freq_range, cycles_dont_drop\n",
    "        )\n",
    "        \n",
    "        # Analyze individual burst spectra\n",
    "        burst_spectral_params = self.analyze_burst_spectra(\n",
    "            original_signal_trimmed, is_burst, sampling_rate, freq_range\n",
    "        )\n",
    "        \n",
    "        # Add averaged spectral parameters if bursts were found\n",
    "        if burst_spectral_params['offsets']:\n",
    "            burst_stats.update({\n",
    "                'mean_offset': float(np.mean(burst_spectral_params['offsets'])),\n",
    "                'std_offset': float(np.std(burst_spectral_params['offsets'])),\n",
    "                'mean_exponent': float(np.mean(burst_spectral_params['exponents'])),\n",
    "                'std_exponent': float(np.std(burst_spectral_params['exponents'])),\n",
    "                'mean_r_squared': float(np.mean(burst_spectral_params['r_squared'])),\n",
    "                'mean_peak_freq': float(np.mean(burst_spectral_params['peak_frequencies'])),\n",
    "                'std_peak_freq': float(np.std(burst_spectral_params['peak_frequencies'])),\n",
    "                'mean_peak_power': float(np.mean(burst_spectral_params['peak_powers'])),\n",
    "                'std_peak_power': float(np.std(burst_spectral_params['peak_powers']))\n",
    "            })\n",
    "        \n",
    "        # Store additional analysis data for plotting\n",
    "        analysis_data = {\n",
    "            'filtered_signal': filtered_signal,\n",
    "            'amplitude_envelope': amplitude_envelope,\n",
    "            'is_burst': is_burst,\n",
    "            'burst_spectral_params': burst_spectral_params\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'statistics': burst_stats,\n",
    "            'analysis_data': analysis_data\n",
    "        }\n",
    "\n",
    "    def _create_empty_band_results(self) -> Dict[str, Any]:\n",
    "        \"\"\"Create empty results structure for failed band analysis.\"\"\"\n",
    "        empty_stats = {\n",
    "            'n_bursts': 0,\n",
    "            'duration_mean': 0.0,\n",
    "            'duration_std': 0.0,\n",
    "            'percent_burst': 0.0,\n",
    "            'bursts_per_second': 0.0\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'statistics': empty_stats,\n",
    "            'analysis_data': None\n",
    "        }\n",
    "\n",
    "    def create_diagnostic_plots(self, \n",
    "                              signal: np.ndarray,\n",
    "                              sampling_rate: float,\n",
    "                              band_results: Dict,\n",
    "                              band_name: str) -> plt.Figure:\n",
    "        \"\"\"\n",
    "        Create diagnostic plots for burst analysis.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        signal : np.ndarray\n",
    "            Original signal\n",
    "        sampling_rate : float\n",
    "            Sampling rate in Hz\n",
    "        band_results : dict\n",
    "            Results from analyze_frequency_band\n",
    "        band_name : str\n",
    "            Name of the frequency band\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        matplotlib.Figure\n",
    "            Figure with diagnostic plots\n",
    "        \"\"\"\n",
    "        analysis_data = band_results['analysis_data']\n",
    "        if analysis_data is None:\n",
    "            # Create empty plot for failed analysis\n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "            ax.text(0.5, 0.5, f'Analysis failed for {band_name} band', \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            return fig\n",
    "        \n",
    "        filtered_signal = analysis_data['filtered_signal']\n",
    "        amplitude_envelope = analysis_data['amplitude_envelope']\n",
    "        is_burst = analysis_data['is_burst']\n",
    "        stats = band_results['statistics']\n",
    "        \n",
    "        # Create time axis\n",
    "        time_axis = np.arange(len(filtered_signal)) / sampling_rate\n",
    "        \n",
    "        # Create figure with subplots\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(15, 10), sharex=True)\n",
    "        \n",
    "        # Plot 1: Original signal (trimmed to match filtered length)\n",
    "        signal_trimmed = signal[:len(filtered_signal)]\n",
    "        axes[0].plot(time_axis, signal_trimmed, color='#2E4053', alpha=0.7, linewidth=0.8)\n",
    "        axes[0].set_ylabel('Amplitude')\n",
    "        axes[0].set_title(f'{band_name} Band Analysis - Original Signal')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Filtered signal\n",
    "        axes[1].plot(time_axis, filtered_signal, color='#2E4053', linewidth=0.8)\n",
    "        axes[1].set_ylabel('Amplitude')\n",
    "        axes[1].set_title('Band-pass Filtered Signal')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 3: Burst detection\n",
    "        axes[2].plot(time_axis, amplitude_envelope, color='#27AE60', alpha=0.6, \n",
    "                    linewidth=1, label='Amplitude Envelope')\n",
    "        \n",
    "        # Add threshold lines\n",
    "        low_threshold = np.percentile(amplitude_envelope, 50)\n",
    "        high_threshold = np.percentile(amplitude_envelope, 75)\n",
    "        axes[2].axhline(y=high_threshold, color='#C0392B', linestyle='--', \n",
    "                       alpha=0.8, label='High Threshold (75th %ile)')\n",
    "        axes[2].axhline(y=low_threshold, color='#E67E22', linestyle='--', \n",
    "                       alpha=0.8, label='Low Threshold (50th %ile)')\n",
    "        \n",
    "        # Highlight detected bursts\n",
    "        burst_envelope = np.ma.masked_where(~is_burst, amplitude_envelope)\n",
    "        axes[2].plot(time_axis, burst_envelope, color='#E74C3C', \n",
    "                    linewidth=2, label='Detected Bursts')\n",
    "        \n",
    "        axes[2].set_ylabel('Amplitude')\n",
    "        axes[2].set_xlabel('Time (s)')\n",
    "        axes[2].legend(loc='upper right')\n",
    "        axes[2].set_title('Burst Detection Results')\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add statistics text\n",
    "        stats_text = (\n",
    "            f\"Bursts detected: {stats['n_bursts']}\\n\"\n",
    "            f\"Mean duration: {stats['duration_mean']:.3f} s\\n\"\n",
    "            f\"Burst rate: {stats['bursts_per_second']:.3f} bursts/s\\n\"\n",
    "            f\"Time in bursts: {stats['percent_burst']:.1f}%\"\n",
    "        )\n",
    "        \n",
    "        plt.figtext(0.02, 0.02, stats_text, fontsize=10, \n",
    "                   bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\", alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(bottom=0.15)\n",
    "        \n",
    "        return fig\n",
    "\n",
    "    def create_spectral_plot(self, spectral_model: SpectralModel) -> plt.Figure:\n",
    "        \"\"\"Create a plot of the fitted spectral model.\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        spectral_model.plot(ax=ax)\n",
    "        ax.set_xlim(0, 30)  # Focus on relevant frequency range\n",
    "        ax.set_title('Whole-Signal Spectral Analysis')\n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "\n",
    "    def analyze_well_file(self, \n",
    "                         pickle_file_path: Union[str, Path],\n",
    "                         create_plots: bool = False) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Analyze a single well's preprocessed data file.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        pickle_file_path : str or Path\n",
    "            Path to pickle file containing preprocessed data\n",
    "        create_plots : bool\n",
    "            Whether to generate diagnostic plots\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            Complete analysis results for all frequency bands\n",
    "        \"\"\"\n",
    "        pickle_file_path = Path(pickle_file_path)\n",
    "        \n",
    "        try:\n",
    "            # Load preprocessed data\n",
    "            with open(pickle_file_path, 'rb') as f:\n",
    "                processed_data = pickle.load(f)\n",
    "            \n",
    "            # Extract signal and metadata\n",
    "            signal = np.array(processed_data['smoothed'])\n",
    "            sampling_rate = processed_data['new_fs']\n",
    "            spectral_model = processed_data.get('spectral_model', None)\n",
    "            \n",
    "            if len(signal) == 0:\n",
    "                self.logger.warning(f\"Empty signal in {pickle_file_path.name}\")\n",
    "                return self._create_empty_well_results()\n",
    "            \n",
    "            # Initialize results storage\n",
    "            well_results = {\n",
    "                'metadata': {\n",
    "                    'file_name': pickle_file_path.name,\n",
    "                    'sampling_rate': sampling_rate,\n",
    "                    'signal_length': len(signal),\n",
    "                    'duration_seconds': len(signal) / sampling_rate\n",
    "                },\n",
    "                'band_analyses': {},\n",
    "                'whole_signal_spectral': None,\n",
    "                'plots': {} if create_plots else None\n",
    "            }\n",
    "            \n",
    "            # Analyze each frequency band\n",
    "            for band_name, band_params in self.frequency_bands.items():\n",
    "                self.logger.info(f\"Analyzing {band_name} band for {pickle_file_path.name}\")\n",
    "                \n",
    "                try:\n",
    "                    band_results = self.analyze_frequency_band(\n",
    "                        signal, sampling_rate, band_name, band_params\n",
    "                    )\n",
    "                    well_results['band_analyses'][band_name] = band_results\n",
    "                    \n",
    "                    # Create diagnostic plots if requested\n",
    "                    if create_plots:\n",
    "                        plot_fig = self.create_diagnostic_plots(\n",
    "                            signal, sampling_rate, band_results, band_name\n",
    "                        )\n",
    "                        well_results['plots'][f'{band_name}_analysis'] = plot_fig\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"Error analyzing {band_name} band: {str(e)}\")\n",
    "                    well_results['band_analyses'][band_name] = self._create_empty_band_results()\n",
    "            \n",
    "            # Store whole-signal spectral analysis\n",
    "            if spectral_model is not None:\n",
    "                well_results['whole_signal_spectral'] = spectral_model\n",
    "                \n",
    "                if create_plots:\n",
    "                    spectral_fig = self.create_spectral_plot(spectral_model)\n",
    "                    well_results['plots']['whole_signal_spectrum'] = spectral_fig\n",
    "            \n",
    "            return well_results\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error analyzing {pickle_file_path.name}: {str(e)}\")\n",
    "            return self._create_empty_well_results()\n",
    "\n",
    "    def _create_empty_well_results(self) -> Dict[str, Any]:\n",
    "        \"\"\"Create empty results structure for failed well analysis.\"\"\"\n",
    "        return {\n",
    "            'metadata': {'error': 'Analysis failed'},\n",
    "            'band_analyses': {},\n",
    "            'whole_signal_spectral': None,\n",
    "            'plots': None\n",
    "        }\n",
    "\n",
    "    def extract_experimental_info(self, file_path: Path) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Extract experimental information from file/folder naming conventions.\n",
    "        \n",
    "        This method should be customized based on your naming conventions.\n",
    "        \"\"\"\n",
    "        file_name = file_path.stem\n",
    "        folder_name = file_path.parent.name\n",
    "        \n",
    "        # Extract well information\n",
    "        well_parts = file_name.split('_')\n",
    "        well_number = well_parts[0].lower() if well_parts else 'unknown'\n",
    "        well_name = self.platemap.get(well_number, f\"Unknown-{well_number}\")\n",
    "        \n",
    "        # Extract timepoint/condition information from folder name\n",
    "        # Customize this logic based on your naming conventions\n",
    "        timepoint = 'unknown'\n",
    "        condition = 'unknown'\n",
    "        \n",
    "        folder_parts = folder_name.split('_')\n",
    "        if len(folder_parts) >= 2:\n",
    "            # Example logic - adapt to your naming scheme\n",
    "            if folder_name.endswith('_PTX'):\n",
    "                timepoint = folder_parts[-2] if len(folder_parts) > 1 else 'unknown'\n",
    "                condition = 'PTX'\n",
    "            elif folder_name.endswith('_Eggan'):\n",
    "                timepoint = folder_parts[-2] if len(folder_parts) > 1 else 'unknown'\n",
    "                condition = 'Eggan'\n",
    "            elif '_' in folder_name:\n",
    "                timepoint = folder_parts[-1]\n",
    "                condition = '_'.join(folder_parts[:-1])\n",
    "        \n",
    "        return {\n",
    "            'well_number': well_number,\n",
    "            'well_name': well_name,\n",
    "            'timepoint': timepoint,\n",
    "            'condition': condition\n",
    "        }\n",
    "\n",
    "    def compile_results_to_dataframe(self, well_results: Dict[str, Any], \n",
    "                                   experimental_info: Dict[str, str]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Compile analysis results into a flat dictionary suitable for DataFrame conversion.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        well_results : dict\n",
    "            Results from analyze_well_file\n",
    "        experimental_info : dict\n",
    "            Experimental metadata\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            Flattened results dictionary\n",
    "        \"\"\"\n",
    "        compiled_results = {\n",
    "            'Well': experimental_info['well_number'],\n",
    "            'Well_name': experimental_info['well_name'],\n",
    "            'Timepoint': experimental_info['timepoint'],\n",
    "            'Condition': experimental_info['condition']\n",
    "        }\n",
    "        \n",
    "        # Add whole-signal spectral parameters\n",
    "        spectral_model = well_results.get('whole_signal_spectral')\n",
    "        if spectral_model is not None:\n",
    "            try:\n",
    "                offset, exponent = spectral_model.get_params('aperiodic_params')\n",
    "                compiled_results.update({\n",
    "                    'Offset': float(offset),\n",
    "                    'Exponent': float(exponent),\n",
    "                    'R_squared': float(spectral_model.r_squared_)\n",
    "                })\n",
    "                \n",
    "                # Add band-specific SNR and peak frequencies from whole signal\n",
    "                frequencies = spectral_model.freqs\n",
    "                flattened_spectrum = spectral_model._spectrum_flat\n",
    "                \n",
    "                for band_name, band_params in self.frequency_bands.items():\n",
    "                    freq_range = band_params['freq_range']\n",
    "                    band_mask = ((frequencies >= freq_range[0]) & \n",
    "                               (frequencies <= freq_range[1]))\n",
    "                    \n",
    "                    if np.any(band_mask):\n",
    "                        band_spectrum = flattened_spectrum[band_mask]\n",
    "                        band_frequencies = frequencies[band_mask]\n",
    "                        \n",
    "                        max_idx = np.argmax(band_spectrum)\n",
    "                        max_snr = float(band_spectrum[max_idx])\n",
    "                        peak_freq = float(band_frequencies[max_idx])\n",
    "                        \n",
    "                        compiled_results[f\"{band_name}_SNR\"] = max_snr\n",
    "                        compiled_results[f\"{band_name}_peak_frequency\"] = peak_freq\n",
    "                    else:\n",
    "                        compiled_results[f\"{band_name}_SNR\"] = float('nan')\n",
    "                        compiled_results[f\"{band_name}_peak_frequency\"] = float('nan')\n",
    "                        \n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"Error extracting spectral parameters: {str(e)}\")\n",
    "        \n",
    "        # Add burst analysis results for each frequency band\n",
    "        band_analyses = well_results.get('band_analyses', {})\n",
    "        \n",
    "        for band_name, band_results in band_analyses.items():\n",
    "            band_stats = band_results.get('statistics', {})\n",
    "            \n",
    "            # Required burst statistics\n",
    "            required_keys = ['duration_mean', 'n_bursts', 'bursts_per_second', \n",
    "                           'percent_burst', 'duration_std']\n",
    "            \n",
    "            # Add basic burst statistics\n",
    "            for key in required_keys:\n",
    "                if key in band_stats:\n",
    "                    if key == 'n_bursts':\n",
    "                        compiled_results[f\"{band_name}_Burst_Number\"] = int(band_stats[key])\n",
    "                    elif key == 'duration_mean':\n",
    "                        compiled_results[f\"{band_name}_Mean_Burst_Duration\"] = float(band_stats[key])\n",
    "                    elif key == 'bursts_per_second':\n",
    "                        compiled_results[f\"{band_name}_Burst_Frequency\"] = float(band_stats[key])\n",
    "                    elif key == 'percent_burst':\n",
    "                        compiled_results[f\"{band_name}_Percent_Burst\"] = float(band_stats[key])\n",
    "                    elif key == 'duration_std':\n",
    "                        compiled_results[f\"{band_name}_Duration_Std\"] = float(band_stats[key])\n",
    "                else:\n",
    "                    # Set default values for missing statistics\n",
    "                    default_val = 0 if key == 'n_bursts' else 0.0\n",
    "                    compiled_results[f\"{band_name}_{key}\"] = default_val\n",
    "            \n",
    "            # Add per-burst spectral parameters if available\n",
    "            spectral_keys = ['mean_offset', 'std_offset', 'mean_exponent', 'std_exponent',\n",
    "                           'mean_r_squared', 'mean_peak_freq', 'std_peak_freq', \n",
    "                           'mean_peak_power', 'std_peak_power']\n",
    "            \n",
    "            for key in spectral_keys:\n",
    "                if key in band_stats:\n",
    "                    # Convert camelCase to readable format\n",
    "                    formatted_key = key.replace('_', ' ').title().replace(' ', '_')\n",
    "                    compiled_results[f\"{band_name}_Burst_{formatted_key}\"] = float(band_stats[key])\n",
    "        \n",
    "        return compiled_results\n",
    "\n",
    "    def save_plots(self, plots: Dict[str, plt.Figure], \n",
    "                  output_folder: Path, \n",
    "                  file_prefix: str):\n",
    "        \"\"\"\n",
    "        Save analysis plots to files.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        plots : dict\n",
    "            Dictionary of plot names to matplotlib figures\n",
    "        output_folder : Path\n",
    "            Directory to save plots\n",
    "        file_prefix : str\n",
    "            Prefix for plot filenames\n",
    "        \"\"\"\n",
    "        output_folder.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for plot_name, figure in plots.items():\n",
    "            try:\n",
    "                plot_path = output_folder / f\"{file_prefix}_{plot_name}.png\"\n",
    "                figure.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "                plt.close(figure)\n",
    "                self.logger.info(f\"Saved plot: {plot_path}\")\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error saving plot {plot_name}: {str(e)}\")\n",
    "\n",
    "    def process_folder(self, \n",
    "                      input_folder: Union[str, Path],\n",
    "                      create_plots: bool = False,\n",
    "                      plot_patterns: Optional[List[str]] = None) -> Tuple[List[Dict], List[Dict]]:\n",
    "        \"\"\"\n",
    "        Process all pickle files in a folder.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_folder : str or Path\n",
    "            Folder containing pickle files\n",
    "        create_plots : bool\n",
    "            Whether to generate diagnostic plots\n",
    "        plot_patterns : list, optional\n",
    "            List of well patterns to plot (e.g., ['well55', 'well56']). \n",
    "            If None, plots all wells when create_plots=True.\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        tuple\n",
    "            (results_list, errors_list)\n",
    "        \"\"\"\n",
    "        input_folder = Path(input_folder)\n",
    "        results_list = []\n",
    "        errors_list = []\n",
    "        \n",
    "        # Setup plots directory if needed\n",
    "        plots_folder = None\n",
    "        if create_plots:\n",
    "            plots_folder = self.plots_dir / input_folder.name\n",
    "            plots_folder.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Process each pickle file\n",
    "        pickle_files = list(input_folder.glob('*.pkl'))\n",
    "        self.logger.info(f\"Processing {len(pickle_files)} files in {input_folder.name}\")\n",
    "        \n",
    "        for pickle_file in pickle_files:\n",
    "            try:\n",
    "                # Extract experimental information\n",
    "                experimental_info = self.extract_experimental_info(pickle_file)\n",
    "                \n",
    "                # Determine if we should create plots for this well\n",
    "                should_plot = False\n",
    "                if create_plots:\n",
    "                    if plot_patterns is None:\n",
    "                        should_plot = True\n",
    "                    else:\n",
    "                        well_name = experimental_info['well_number'].lower()\n",
    "                        should_plot = any(well_name.startswith(pattern.lower()) \n",
    "                                        for pattern in plot_patterns)\n",
    "                \n",
    "                # Analyze the well\n",
    "                well_results = self.analyze_well_file(pickle_file, create_plots=should_plot)\n",
    "                \n",
    "                # Compile results for DataFrame\n",
    "                compiled_results = self.compile_results_to_dataframe(\n",
    "                    well_results, experimental_info\n",
    "                )\n",
    "                results_list.append(compiled_results)\n",
    "                \n",
    "                # Save plots if generated\n",
    "                if should_plot and well_results.get('plots'):\n",
    "                    self.save_plots(\n",
    "                        well_results['plots'], \n",
    "                        plots_folder, \n",
    "                        pickle_file.stem\n",
    "                    )\n",
    "                \n",
    "                self.logger.info(f\"Successfully processed {pickle_file.name}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_info = {\n",
    "                    'file': str(pickle_file),\n",
    "                    'error': str(e),\n",
    "                    'error_type': type(e).__name__,\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "                errors_list.append(error_info)\n",
    "                self.logger.error(f\"Error processing {pickle_file.name}: {str(e)}\")\n",
    "        \n",
    "        return results_list, errors_list\n",
    "\n",
    "    def process_experiment(self, \n",
    "                          input_base_folder: Union[str, Path],\n",
    "                          experiment_id: str = None,\n",
    "                          create_plots: bool = False,\n",
    "                          plot_patterns: Optional[List[str]] = None) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Process an entire experiment with multiple timepoints/conditions.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_base_folder : str or Path\n",
    "            Base folder containing subfolders with pickle files\n",
    "        experiment_id : str, optional\n",
    "            Identifier for the experiment (used in output filenames)\n",
    "        create_plots : bool\n",
    "            Whether to generate diagnostic plots\n",
    "        plot_patterns : list, optional\n",
    "            List of well patterns to plot\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            Processing summary and statistics\n",
    "        \"\"\"\n",
    "        input_base_folder = Path(input_base_folder)\n",
    "        \n",
    "        if experiment_id is None:\n",
    "            experiment_id = input_base_folder.name\n",
    "        \n",
    "        # Initialize aggregation lists\n",
    "        all_results = []\n",
    "        all_errors = []\n",
    "        processing_stats = {}\n",
    "        \n",
    "        # Process each subfolder\n",
    "        subfolders = [f for f in input_base_folder.iterdir() if f.is_dir()]\n",
    "        self.logger.info(f\"Processing experiment '{experiment_id}' with {len(subfolders)} timepoints\")\n",
    "        \n",
    "        for subfolder in sorted(subfolders):\n",
    "            try:\n",
    "                self.logger.info(f\"Processing folder: {subfolder.name}\")\n",
    "                \n",
    "                folder_results, folder_errors = self.process_folder(\n",
    "                    subfolder, create_plots, plot_patterns\n",
    "                )\n",
    "                \n",
    "                all_results.extend(folder_results)\n",
    "                all_errors.extend(folder_errors)\n",
    "                \n",
    "                processing_stats[subfolder.name] = {\n",
    "                    'processed': len(folder_results),\n",
    "                    'failed': len(folder_errors)\n",
    "                }\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error processing folder {subfolder.name}: {str(e)}\")\n",
    "                all_errors.append({\n",
    "                    'folder': str(subfolder),\n",
    "                    'error': str(e),\n",
    "                    'error_type': type(e).__name__,\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                })\n",
    "        \n",
    "        # Create comprehensive results DataFrame\n",
    "        if all_results:\n",
    "            results_df = pd.DataFrame(all_results)\n",
    "            \n",
    "            # Sort by well number for consistent ordering\n",
    "            if 'Well' in results_df.columns:\n",
    "                results_df['well_sort_key'] = results_df['Well'].str.extract(r'(\\d+)').astype(int)\n",
    "                results_df = results_df.sort_values(['well_sort_key', 'Timepoint'])\n",
    "                results_df = results_df.drop('well_sort_key', axis=1)\n",
    "            \n",
    "            # Save results\n",
    "            output_file = self.output_dir / f\"{experiment_id}_burst_analysis_results.csv\"\n",
    "            output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "            results_df.to_csv(output_file, index=False)\n",
    "            self.logger.info(f\"Saved combined results to {output_file}\")\n",
    "        \n",
    "        # Save error log if there were errors\n",
    "        if all_errors:\n",
    "            error_file = self.output_dir / f\"{experiment_id}_analysis_errors.json\"\n",
    "            with open(error_file, 'w') as f:\n",
    "                json.dump({\n",
    "                    'experiment_id': experiment_id,\n",
    "                    'processing_date': datetime.now().isoformat(),\n",
    "                    'errors': all_errors\n",
    "                }, f, indent=2)\n",
    "            self.logger.info(f\"Saved error log to {error_file}\")\n",
    "        \n",
    "        # Compile summary statistics\n",
    "        total_processed = sum(stats['processed'] for stats in processing_stats.values())\n",
    "        total_failed = sum(stats['failed'] for stats in processing_stats.values())\n",
    "        \n",
    "        summary = {\n",
    "            'experiment_id': experiment_id,\n",
    "            'total_files_processed': total_processed,\n",
    "            'total_files_failed': total_failed,\n",
    "            'folder_statistics': processing_stats,\n",
    "            'output_files': {\n",
    "                'results_csv': str(output_file) if all_results else None,\n",
    "                'error_log': str(error_file) if all_errors else None\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.logger.info(f\"Experiment processing complete: {total_processed} successful, {total_failed} failed\")\n",
    "        return summary\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Example usage of the OscillatoryBurstAnalyzer.\n",
    "    \n",
    "    Configure the paths and parameters below to match your experimental setup.\n",
    "    \"\"\"\n",
    "    # Configuration\n",
    "    base_directory = Path(\"your_data_directory_here\")  # Update this path\n",
    "    processed_data_folder = base_directory / \"spectral_analysis\"  # Folder with pickle files\n",
    "    \n",
    "    # Custom frequency bands (optional - remove to use defaults)\n",
    "    custom_bands = {\n",
    "        'Delta': {'freq_range': (1, 4), 'min_cycles': 8, 'cycles_dont_drop': 3},\n",
    "        'Theta': {'freq_range': (4, 8), 'min_cycles': 16, 'cycles_dont_drop': 4},\n",
    "        'Alpha': {'freq_range': (8, 13), 'min_cycles': 24, 'cycles_dont_drop': 5},\n",
    "        'Beta': {'freq_range': (13, 30), 'min_cycles': 32, 'cycles_dont_drop': 6}\n",
    "    }\n",
    "    \n",
    "    # Initialize analyzer\n",
    "    analyzer = OscillatoryBurstAnalyzer(\n",
    "        base_path=base_directory,\n",
    "        output_subdir=\"burst_analysis_results\",\n",
    "        frequency_bands=custom_bands  # Remove this line to use defaults\n",
    "    )\n",
    "    \n",
    "    # Process entire experiment\n",
    "    if processed_data_folder.exists():\n",
    "        # Option 1: Process with plots for specific wells\n",
    "        summary = analyzer.process_experiment(\n",
    "            processed_data_folder,\n",
    "            experiment_id=\"drug_screen_experiment\",\n",
    "            create_plots=True,\n",
    "            plot_patterns=['well55', 'well56']  # Only plot these wells\n",
    "        )\n",
    "        \n",
    "        # Option 2: Process without plots (faster)\n",
    "        # summary = analyzer.process_experiment(\n",
    "        #     processed_data_folder,\n",
    "        #     experiment_id=\"drug_screen_experiment\",\n",
    "        #     create_plots=False\n",
    "        # )\n",
    "        \n",
    "        print(f\"Processing complete. Summary: {summary}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Input folder {processed_data_folder} does not exist. Please update the path.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "team_ndd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
